{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917f879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from math import log10, sqrt,log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5725b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "combined_results_T5 = pd.read_csv('WikiHow_sample_all_withsummary.csv')\n",
    "combined_results_BERT = pd.read_csv('combined_results_BERT_bm25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ed8b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(documents):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(documents)\n",
    "    tokens =  [token.lower() for token in tokens if token.isalpha()]\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token, pos='v') for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a617652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    new_tokens = []\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            new_tokens.append(token)\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa499e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inverted_index(data):\n",
    "    n = len(data[data['summary']!='empty'])\n",
    "    df = data.loc[:n,:]\n",
    "    inverted_index = {}\n",
    "    for i in range(len(df)):\n",
    "        if isinstance(df.loc[i,'summary'], str) == False:\n",
    "            continue\n",
    "        tokens = preprocess(df.loc[i,'summary'])\n",
    "        tokens_dist = nltk.FreqDist(tokens)\n",
    "        for voc in tokens_dist.keys():\n",
    "            if voc not in inverted_index.keys():\n",
    "                inverted_index[voc] = [1, tokens_dist[voc]]\n",
    "            else:\n",
    "                inverted_index[voc][0] += 1\n",
    "                inverted_index[voc][1] += tokens_dist[voc]\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index_T5 = get_inverted_index(combined_results_T5)\n",
    "inverted_index_BERT = get_inverted_index(combined_results_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c8c5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(data):\n",
    "    total_len = 0\n",
    "    for i in range(len(data)):\n",
    "        if isinstance(data.loc[i,'summary'], str) == False:\n",
    "            continue\n",
    "        passage_len = len(preprocess(data.loc[i,'summary']))\n",
    "        total_len += passage_len\n",
    "    total_pa = len(data)\n",
    "    return total_len/total_pa, total_pa\n",
    "\n",
    "avdl_t5, N_t5 = length(combined_results_T5)\n",
    "avdl_bert, N_bert = length(combined_results_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5ae4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(data, inverted_index,avdl,N, k1 = 1.2, k2 = 100,b = 0.75):\n",
    "    scores = np.zeros((len(data),3))\n",
    "    for i in tqdm(range(len(data))):\n",
    "        if isinstance(data.loc[i,'summary'], str) == False:\n",
    "            continue\n",
    "        tokens_p = preprocess(data.loc[i,'summary'])\n",
    "        tokens_q = preprocess(data.loc[i,'title'])\n",
    "        f_p = nltk.FreqDist(tokens_p)\n",
    "        f_q = nltk.FreqDist(tokens_q)\n",
    "        dl = len(tokens_p)\n",
    "        K = k1*((1-b)+b*(dl/avdl))\n",
    "        bm25 = 0\n",
    "        for token in f_q.keys():\n",
    "            if token in inverted_index.keys():\n",
    "                term1 =  log((N-inverted_index[token][0]+0.5)/(inverted_index[token][0]+0.5))\n",
    "                term2 = (k1+1)*f_p[token]/(K+f_p[token])\n",
    "                term3 = (k2+1)*f_q[token]/(k2+f_q[token])\n",
    "                bm25 += term1 *term2 *term3\n",
    "        data.loc[i,'bm25'] = bm25\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88e0555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 49642/49642 [00:36<00:00, 1374.88it/s]\n"
     ]
    }
   ],
   "source": [
    "combined_results_T5 = BM25(combined_results_T5, inverted_index,avdl_t5,N_t5, k1 = 1.2, k2 = 100,b = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81a6ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 44400/44400 [00:52<00:00, 843.13it/s]\n"
     ]
    }
   ],
   "source": [
    "combined_results_BERT = BM25(combined_results_BERT, inverted_index_BERT,avdl_bert,N_bert, k1 = 1.2, k2 = 100,b = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c3391ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save BM25 scores\n",
    "combined_results_T5.to_csv('WikiHow_sample_all_withsummary.csv')\n",
    "combined_results_BERT.to_csv('combined_results_BERT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "788d2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge BERT and T5 results together\n",
    "bm25_compare = pd.merge(WikiHow_sample_all, combined_results_BERT, on='title')\n",
    "bm25_compare = bm25_compare[bm25_compare['summary_length'] != 0]\n",
    "bm25_compare = bm25_compare.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a6a6dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare T5 and BERT performance\n",
    "count_t5 = 0\n",
    "count_bert = 0\n",
    "equal = 0\n",
    "test_count = 0 \n",
    "\n",
    "for i,  (x,y) in enumerate(zip(bm25_compare['bm25_x'],bm25_compare['bm25_y'])):\n",
    "    test_count += 1\n",
    "    if x>y:\n",
    "        count_t5 +=1\n",
    "    elif x<y:\n",
    "        count_bert +=1\n",
    "    else:\n",
    "        equal +=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "952d6658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24493951371421727"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal/len(bm25_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4012643b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31596598395017367"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_t5/len(bm25_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cebda04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43909450233560904"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_bert/len(bm25_compare)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
